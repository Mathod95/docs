---
title: KIND
date: 2025-12-03
draft: true
categories:
  - Kind
tags:
  - Kind
sources:
  - https://mcvidanagama.medium.com/set-up-a-multi-node-kubernetes-cluster-locally-using-kind-eafd46dd63e5
  - https://itnext.io/kubernetes-multi-cluster-implementation-in-under-10-minutes-2927952fb84c
  - https://medium.com/ibm-cloud/gitops-quick-start-with-kubernetes-kind-cluster-5677f94adf69
  - https://shashanksrivastava.medium.com/install-configure-argo-cd-on-kind-kubernetes-cluster-f0fee69e5ac4
  - https://magmax.org/en/blog/argocd/
  - https://phoenixnap.com/kb/kubernetes-kind
  - https://blog.kubesimplify.com/getting-started-with-kind-creating-a-multi-node-local-kubernetes-cluster
  - https://developers.redhat.com/articles/2023/01/16/how-prevent-computer-overload-remote-kind-clusters
  - https://linuxconcept.com/creating-a-multi-node-cluster-with-kind/
  - https://docs.dapr.io/operations/hosting/kubernetes/cluster/setup-kind/
  - https://www.baeldung.com/ops/kubernetes-kind
  - https://itnext.io/starting-local-kubernetes-using-kind-and-docker-c6089acfc1c0
  - https://mcvidanagama.medium.com/set-up-a-multi-node-kubernetes-cluster-locally-using-kind-eafd46dd63e5
---

![](../../assets/images/kind/kind.png)

## Introduction
[Kind](https://kind.sigs.k8s.io/) *(Kubernetes in Docker)* est un outil qui facilitent l'exÃ©cution de clusters Kubernetes locaux en utilisant des container Docker ! Cette outils Ã  Ã©tÃ© crÃ©er principalement pour tester Kubernetes.
Il existe de multiples solution pour dÃ©ployer un cluster Kubernetes. Kubeadm, Kops, Minikube pour ne citer qu'eux ! Cependant la plus part de ces solutions sont parfois assez limitÃ© en terme de configuration, voir complexe Ã  mettre en place...
La documentation de kind est facile Ã  comprendre, pour plus de dÃ©tails, rÃ©fÃ©rez vous Ã  ceÂ [lien](https://kind.sigs.k8s.io/docs/user/quick-start/).

<!-- more -->

### Objectifs
- Apprendre Ã  installer kind
- CrÃ©er un cluster single ou multi node
- DÃ©ployer une version spÃ©cifique de Kubernetes
- Supprimer un Cluster single ou multi node
- Exporter les logs d'un cluster kind
- DÃ©ployer une application

### PrÃ©requis
- Docker/Docker Desktop

### Ma configuration
- Debian 12
- kubectl
- [Docker desktop](https://desktop.docker.com/win/main/amd64/Docker%20Desktop%20Installer.exe?utm_source=docker&utm_medium=webreferral&utm_campaign=dd-smartbutton&utm_location=module) 4.28.0

---

## Installation de Kind

### PrÃ©requis

Le seul prÃ©requis pour utiliser Kind est d'avoir Docker d'installer. Dans notre cas nous utiliserons Docker-Desktop sous Windows et nous le lieront a un WSL Debian. Pour les autres systÃ¨mes je vous invite Ã  suivreÂ [la documentation officiel](https://kind.sigs.k8s.io/docs/user/quick-start/)

Sur Debian pour l'installation nous utiliserons les commandes suivante:

=== "Brew"

    ```shell hl_lines="1"
    brew install kind
    ```
    
    !!! info

        The following are community supported efforts. The kind maintainers are not involved in the creation of these packages, and the upstream community makes no claims on the validity, safety, or content of them.

=== "Release Binaries"
    
    ```shell hl_lines="1 7 8"
    [ $(uname -m) = x86_64 ] && curl -Lo ./kind https://kind.sigs.k8s.io/dl/latest/kind-linux-amd64
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
    100    97  100    97    0     0    822      0 --:--:-- --:--:-- --:--:--   829
      0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
    100 6304k  100 6304k    0     0  6132k      0  0:00:01  0:00:01 --:--:-- 6132k
    chmod +x ./kind
    sudo mv ./kind /usr/local/bin/kind
    ```

Afin de s'assurer que Kind est bien installer nous pouvons utiliser la commandeÂ `kind version`Â pour s'assurer de son bon fonctionnement.

```shell hl_lines="1"
kind version
kind v0.30.0 go1.25.4 linux/amd64
```

## CrÃ©ation d'un cluster

=== "Single Node"

    Aucune configuration nÃ©cÃ©ssaire pour crÃ©er un cluster single node juste la commande suivante:

    ```shell hl_lines="1"
    kind create cluster
    Creating cluster "kind" ...
     âœ“ Ensuring node image (kindest/node:v1.34.0) ğŸ–¼
     âœ“ Preparing nodes ğŸ“¦
     âœ“ Writing configuration ğŸ“œ
     âœ“ Starting control-plane ğŸ•¹
     âœ“ Installing CNI ğŸ”Œ
     âœ“ Installing StorageClass ğŸ’¾
    Set kubectl context to "kind-kind"
    You can now use your cluster with:

    kubectl cluster-info --context kind-kind

    Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community ğŸ™‚
    ```

    La crÃ©ation du cluster ce feras avec une image prÃ©-built hÃ©berger surÂ [Docker Hub](https://hub.docker.com/r/kindest/node/)

    Vous switcher automatiqment sur le context du cluster que vous venez de crÃ©er.  
    Vous pouvez utiliser la commandeÂ `kubectl get nodes`Â pour vÃ©rifier que votre cluster fonctionne correctement.

    ```shell hl_lines="1"
    kubectl get nodes
    NAME                 STATUS   ROLES           AGE     VERSION
    kind-control-plane   Ready    control-plane   5m28s   v1.34.0
    ```

=== "Multi Node"

    Pour un cluster avec plusieurs nodes un fichier de configuration comme suit seras nÃ©cÃ©ssaire

    ```yaml linenums="1" title="multiNode.yaml"
    apiVersion: kind.x-k8s.io/v1alpha4
    kind: Cluster
    nodes:
    - role: control-plane
    - role: control-plane
    - role: control-plane
    - role: worker
    - role: worker
    - role: worker
    ```

    Dans ce fichier de configuration, nous crÃ©ons un cluster multi-nodes avec 3 control-plane et 3 worker

    Pour la commande on ajoute juste le flag `--config` et le chemin de notre configuration

    ```shell hl_lines="1"
    kind create cluster --config multiNode.yaml
    Creating cluster "kind" ...
     âœ“ Ensuring node image (kindest/node:v1.34.0) ğŸ–¼
     âœ“ Preparing nodes ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦ ğŸ“¦
     âœ“ Configuring the external load balancer âš–
     âœ“ Writing configuration ğŸ“œ
     âœ“ Starting control-plane ğŸ•¹
     âœ“ Installing CNI ğŸ”Œ
     âœ“ Installing StorageClass ğŸ’¾
     âœ“ Joining more control-plane nodes ğŸ®
     âœ“ Joining worker nodes ğŸšœ
    Set kubectl context to "kind-kind"
    You can now use your cluster with:

    kubectl cluster-info --context kind-kind

    Not sure what to do next? ğŸ˜…  Check out https://kind.sigs.k8s.io/docs/user/quick-start/
    ```

    La crÃ©ation du cluster ce feras avec une image prÃ©-built hÃ©berger surÂ [Docker Hub](https://hub.docker.com/r/kindest/node/)

    Vous switcher automatiqment sur le context du cluster que vous venez de crÃ©er.  
    Vous pouvez utiliser la commandeÂ `kubectl get nodes`Â pour vÃ©rifier que votre cluster fonctionne correctement.

    ```shell hl_lines="1"
    kubectl get nodes
    NAME                  STATUS     ROLES           AGE   VERSION
    kind-control-plane    Ready      control-plane   65s   v1.34.0
    kind-control-plane2   Ready      control-plane   65s   v1.34.0
    kind-control-plane3   Ready      control-plane   65s   v1.34.0
    kind-worker           Ready      <none>          65s   v1.34.0
    kind-worker2          Ready      <none>          65s   v1.34.0
    kind-worker3          Ready      <none>          65s   v1.34.0
    ```

## Cluster Configurations
Par dÃ©faut le fichier de configuration de votre cluster se trouveras dans ${HOME}/.kube/config

```shell hl_lines="1"
cat ${HOME}/.kube/config
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUMvakNDQWVhZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJME1ESXhNREUwTXpjd09Wb1hEVE0wTURJd056RTBNemN3T1Zvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTWZmCjk5YmxnV1FFN1RBWXhSNmd5Yk9PbG0rRFRvdjBMTklUSG5ydDdkTzVydTljK3FvLzNqQzZWcTVseTByZ21odUIKTXgvVVlvd09MWWJrZ21kWkpNS0NENjh6bENFSVRNSHB4Q2xlaXYrdVdkVCtTYWJ2MkkyM2wvVjdsUjFVTzRQRwpJdWNLaFZNT0JGQ1Axci8yMDVPQVJlWDNtSjg0SER2UW03K2RKaWdtVUhVYk9DallidXIzeW9xcldxdXZ5d2hFCmNPaW1aN1hzMVc4WjBpTFF2L2pkYXhzMThqYWMzci9VbUJRa3FCV2ozSUJ2S3o3NHVPWVYxUWNoa0ZEMWJMVkkKSkZKMWc3UmUxazNHWkpUUzRHeEo0RWpoR3NyV01vRmlRT21uWTZneFA5TlpvZ2k2bkNRaWQ1Q0ZteUJnM1ZocAovMkRWcHUrVGNtUktxTlhPMEEwQ0F3RUFBYU5aTUZjd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZCcmVlaHFVOHpkNjlTSXdYaC9FQ1Jwc05HcURNQlVHQTFVZEVRUU8KTUF5Q0NtdDFZbVZ5Ym1WMFpYTXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBQ3hrT2J0L3hXayt2dTdGMTk1UQpNTVpYUWR0alUvNjVidHp1MDZWVU9icEtOZVA0Qzkwb0VNWDBpbzJKbVhlelE2TTJnUGYyb2Z4MEdEOUE1dWxtCjYxWXFmR0ViQ1FzNytRaVFyc1ppbmhDMXI3L3Q1OUpwbkp4VCtVV1NwVkhUSmNnSlFQbXI3QlRDd2tkR3ZscEYKdFgxQTBTUGNPdVJUM2RRM3EvVkJ0b3BGMWhiWUN5S2cyM0t1YUZJZjZmSlY1K2hSNWgreENTNGpUT3Z6RVNqWgprZVhxTmxaM0ZWS0JTQzVZeWhORmhMelNKT3U1ZUJhTU9YVGl2aVg5ckVRcUFRYmlNcWMyVGZlekZWV3VUL0M3Cnc5R0FhamJNTnY4UVZQNU9jc0RDTGRIS1BRTDRpSEUxMHpEVllvRkwyb2JHQXFJMVNJamt0RTVTMFlNTS9uYlcKSFlrPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    server: https://127.0.0.1:40299
  name: kind-kind
contexts:
- context:
    cluster: kind-kind
    user: kind-kind
  name: kind-kind
current-context: kind-kind
kind: Config
preferences: {}
users:
- name: kind-kind
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJRnpiYUxLcDl6MlV3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBeU1UQXhORE0zTURsYUZ3MHlOVEF5TURreE5ETTNNVEZhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXRHU2R2V0liQ2Y0SkpqVXoKNTM2VEh0WGRSeFN6bWVmYWo5L2kvU0xBQ3B0dCtISTBLV2ZOby9SQjB6UmxyMWFaN2UxclRLQUpHNFZLRDhydgpkak9CdDZPZUMwdElUVUQxZndJUGlTbUVRVURxMUhuRURHMnI2a0J3ek82Z0ZEcGxjbFpyV3p0WGRmdXZweXJICkVqOTVLZ0pDS0tmbUIzZFBlcjk5cTVRdU1URGw0MXBZNUhJWUswL3FNTFRsVVFUSnVlQVdqOHViaGVURDBUZDAKdFRBNElIZlA2UkJGWmtGUlJWeUh3N3BsdU4yNlJqOW9QYXVPckNUcWhTdGxtb2NKM1o2dXV4a1BPZkg1YXJ5TwpIbFNNWnJZWDdLVGk0Wmx6bTl1Ymg0b1V2NXhuZHJOajNabWV1S1hubWx3SVNsY0lWSnZTNE5SYWhBOC92TEF2CklPbk5Jd0lEQVFBQm8xWXdWREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RBWURWUjBUQVFIL0JBSXdBREFmQmdOVkhTTUVHREFXZ0JRYTNub2FsUE0zZXZVaU1GNGZ4QWthYkRScQpnekFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBVFhJM3BtenZvZDFTR1BhcGdCTWsyQ3g0OU4vaE92OUgvanNICkc5MUV0VCtYR2FMM1I3WWhIMG8vMm41MVcrTncxazdiY3l4NkJtT0IzNW9OQlJJNHpZS3lOYWZuN0x3UjRCSVAKb1QvZzZaZUJ2bTNhWC9JeDNCTUt1eHFHVmowZHZXREFWRDB1WGdiVE0zSHpOcXc1dnVNZTNyNXNWRmxoWDFoZgpPa2ttTFZXeTZuYXVvZzUxb0hadHNnVk9jNkl4M3lDTEJkeis0RDRSQVVtSTYwdlc4NmN3SUE3UE4yQlNhZlNiClJWMzZrQWduNGFTMmlmQXZCRDNDeFF1N0swYzYzNUx3aXYvR08vMkRSakx0NzV0ZVROdGQ4QXBIKzRsMFQzelMKRFh1VW1qcVZLRHZQL0lYbXVUTStZWXBkdzVZdzg1QXQ4UlhBY012dGQ1c2xSSUo2a3c9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    client-key-data: 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
```

## Utiliser une image node diffÃ©rente
L'utilisation d'une image diffÃ©rente vous permet de changer la version du cluster Kubernetes crÃ©Ã©. Chaque version de Kind supporte une liste spÃ©cifique des versions de Kubernetes, vous pouvez voir la liste des versions supportÃ©es de Kubernetes depuis cetteÂ [page](https://github.com/kubernetes-sigs/kind/releases#:~:text=Images%20pre%2Dbuilt,v1.29.0%40sha256%3Aeaa1450915475849a73a9227b8f201df25e55e268e5d619312131292e324d570).

```shell hl_lines="1"
Images pre-built for this release:

v1.34.0: kindest/node:v1.34.0@sha256:7416a61b42b1662ca6ca89f02028ac133a309a2a30ba309614e8ec94d976dc5a
v1.33.4: kindest/node:v1.33.4@sha256:25a6018e48dfcaee478f4a59af81157a437f15e6e140bf103f85a2e7cd0cbbf2
v1.32.8: kindest/node:v1.32.8@sha256:abd489f042d2b644e2d033f5c2d900bc707798d075e8186cb65e3f1367a9d5a1
v1.31.12: kindest/node:v1.31.12@sha256:0f5cc49c5e73c0c2bb6e2df56e7df189240d83cf94edfa30946482eb08ec57d2
```

Pour spÃ©cifier une autre image, utilisez l'optionÂ `--image`

```shell hl_lines="1"
kind create cluster --image kindest/node:v1.33.4@sha256:25a6018e48dfcaee478f4a59af81157a437f15e6e140bf103f85a2e7cd0cbbf2
```

## Changer le nom context de votre cluster
Par dÃ©faut le context de votre cluster sera nommÃ©Â `kind`. Vous pouvez utiliser le flagÂ `--name`Â pour assigner un nom diffÃ©rent.

```shell hl_lines="1"
kind create cluster --name mathod
Creating cluster "mathod" ...
 âœ“ Ensuring node image (kindest/node:v1.34.0) ğŸ–¼
 âœ“ Preparing nodes ğŸ“¦
 âœ“ Writing configuration ğŸ“œ
 âœ“ Starting control-plane ğŸ•¹
 âœ“ Installing CNI ğŸ”Œ
 âœ“ Installing StorageClass ğŸ’¾
Set kubectl context to "kind-mathod"
You can now use your cluster with:

kubectl cluster-info --context kind-mathod

Thanks for using kind! ğŸ˜Š
```

La commandÂ `kubectl config get-contexts`Â permet de lister les clusters et indiquer le context en cours d'utilisation

```shell hl_lines="1"
â¯ kubectl config get-contexts
CURRENT   NAME           CLUSTER        AUTHINFO       NAMESPACE
          kind-kind      kind-kind      kind-kind      default
*         kind-mathod    kind-mathod    kind-mathod
```

Pour passer d'un cluster Ã  un autre, vous pouvez utiliserÂ `kubectl config use-context <cluster-name>`.

??? tip "Kubectx"

    - kubectx permet de changer rapidement de contexte.
    - kubens permet de basculer facilement entre les namespaces d'un cluster. (intÃ©grer Ã  kubectx)

    ```shell hl_lines="1"
    brew install kubectx
    ```

## Interagir avec le cluster
AprÃ¨s avoir crÃ©Ã© un cluster, vous pouvez utiliser kubectl pour interagir avec ce dernier.

```shell hl_lines="1"
kubectl cluster-info
Kubernetes control plane is running at https://127.0.0.1:32991
CoreDNS is running at https://127.0.0.1:32991/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

Vous pouvez Ã©galement lister tous les containers Kind avec la commande suivante:

```shell hl_lines="1"
docker ps
CONTAINER ID   IMAGE                                COMMAND                  CREATED         STATUS         PORTS                       NAMES
973259b15c3b   kindest/haproxy:v20230606-42a2262b   "haproxy -W -db -f /â€¦"   8 minutes ago   Up 8 minutes   127.0.0.1:39103->6443/tcp   kind-external-load-balancer
6120719d8b42   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes   127.0.0.1:45665->6443/tcp   kind-control-plane2
fd2be64055ab   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes   127.0.0.1:33845->6443/tcp   kind-control-plane
f14296cc3f77   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes   127.0.0.1:40977->6443/tcp   kind-control-plane3
63ba6aa113b6   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes                               kind-worker3
0098259cc8ce   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes                               kind-worker2
a4d8e4971eab   kindest/node:v1.34.0                 "/usr/local/bin/entrâ€¦"   8 minutes ago   Up 8 minutes                               kind-worker
```

## Suppression d'un cluster

Pour supprimer un cluster nous utiliserons la commandeÂ `kind delete clusters <clusterName>`.  

```shell hl_lines="2 9"
â¯ kind delete clusters kind
Deleted nodes: ["kind-external-load-balancer" "kind-control-plane2" "kind-control-plane" "kind-control-plane3" "kind-worker3" "kind-worker2" "kind-worker"]
Deleted clusters: ["kind"]
```

## Dynamic Volume Provisioning

Le provisionnement dynamique des volumes dans Kubernetes est un mÃ©canisme qui permet de crÃ©er des volumes de stockage Ã  la demande. Pour ce faire, le cluster Kubernetes utilise le concept de classe de stockage, qui fait abstraction des dÃ©tails du stockage sous-jacent. Les administrateurs du cluster doivent appeler manuellement leur fournisseur de cloud ou de stockage, puis crÃ©er des objets Persistent Volume dans Kubernetes sans provisionnement dynamique.

Une Storage Class est par dÃ©faut prÃ©configurÃ©e lorsque vous crÃ©ez le cluster Kind. Pour voir la liste des classes de stockage disponibles, utilisez la commande kubectl get sc.

```shell hl_lines="1"
NAME                 PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
standard (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  11d
```

WaitforFirstConsumer indique que leÂ **pvc**Â (persistent volume claim) ne sera pas liÃ© tant qu'il ne sera pas attachÃ© Ã  un pod.

Nous allons maintenant crÃ©ez un fichier PVC en utilisant le code ci-dessous.

```yaml title="pvc.yaml" linenums="1"
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-test
spec:
  storageClassName: standard
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Mi
```

Enregistrez ce fichier sous le nom deÂ `pvc.yaml`Â et exÃ©cutez la commande suivante pour crÃ©er uneÂ **demande de volume persistant**Â Ã  partir de ce fichier pvc. yaml :

```shell hl_lines="1"
kubectl create -f pvc.yaml
```

Create another yaml file for the busybox pod by using the given below code and save it asÂ `busybox.yaml`.

```yaml title="pod.yaml" linenums="1"
apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  volumes:
  - name: host-volume
    persistentVolumeClaim:
      claimName: pvc-test
  containers:
  - image: busybox
    name: busybox
    command: ["/bin/sh"]
    args: ["-c", "sleep 600"]
    volumeMounts:
    - name: host-volume
      mountPath: /mydata
```

Run the following command to create a pod:

```shell hl_lines="1"
kubectl create-f busybox.yaml
```

Run the following commands to validate the persistent volume or persistent volume claim created, and to check whether the pod is running or not:

```shell hl_lines="1 3"
kubectl get pv,pvc

kubectl get pods
```

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1678126464504/2e3d4256-6163-4d72-ad18-8ec2f72df703.png?auto=compress,format&format=webp)

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1678126521737/6a090583-ae64-4acc-b097-b4f857acd350.png?auto=compress,format&format=webp)

Now we've actually built a multi-node pvc-backed cluster and mounted it on busybox.

You must expose your service after it has been deployed to Kubernetes so that your users can access it. The cluster can be accessed from outside in three ways: ingress, load balancer, and node port.

## Exporter les logs d'un cluster

Vous pouvez exporter les logs de Kind au besoin avec la commande suivanteÂ `kind export logs`.  
Encore une fois vous pouvez utiliser l'optionÂ `--name <clusterName>`.

```shell hl_lines="2 9"
# Par dÃ©faut si aucun nom na Ã©tÃ© spÃ©cifiÃ©
kind export logs
Exporting logs for cluster "kind" to:
/tmp/606883079

OU

# Si un nom Ã  Ã©tÃ© spÃ©cifiÃ© avec la commande "kind create cluster --name my-little-kubernetes"
kind export logs --name my-little-kubernetes
Exporting logs for cluster "my-little-kubernetes" to:
/tmp/248121554
```

La structure des logs ressemblera plus ou moins Ã  ceci:

```shell
.
â”œâ”€â”€ docker-info.txt
â”œâ”€â”€ kind-version.txt
â””â”€â”€ my-little-kubernetes-control-plane
    â”œâ”€â”€ alternatives.log
    â”œâ”€â”€ containerd.log
    â”œâ”€â”€ containers
    â”‚Â Â  â”œâ”€â”€ coredns-5d78c9869d-m6zfl_kube-system_coredns-86169c2cf303ff450b9c634428486aad040bbc78c7ba386f15c9c0206e81cf2c.log
    â”‚Â Â  â”œâ”€â”€ coredns-5d78c9869d-vlv59_kube-system_coredns-d66e4fa61d209f45a0b8d6394a363722058b98d62e7fb3fb08ec9300b399b8f8.log
    â”‚Â Â  â”œâ”€â”€ etcd-my-little-kubernetes-control-plane_kube-system_etcd-656a77b115a3659616def413134537a25de8cdc1bebc804361136ad86036bf51.log
    â”‚Â Â  â”œâ”€â”€ kindnet-n6jll_kube-system_kindnet-cni-32a1650c6e6ec313957bfab06a1f782c48ca2d21093a4f9cfa92d75955442ab7.log
    â”‚Â Â  â”œâ”€â”€ kube-apiserver-my-little-kubernetes-control-plane_kube-system_kube-apiserver-20e26af6ee88986ab750a3d11fdf3cca10e40763e9c6a489156a672f9603983a.log
    â”‚Â Â  â”œâ”€â”€ kube-controller-manager-my-little-kubernetes-control-plane_kube-system_kube-controller-manager-9c0f721140920ae0475a8dd52ca95240d764209f7509ff86b0901a623c801686.log
    â”‚Â Â  â”œâ”€â”€ kube-proxy-wmvm5_kube-system_kube-proxy-13f3024cf7ef0eb521cc643a263120520570ac2c2b153d7c285942e17fbff396.log
    â”‚Â Â  â”œâ”€â”€ kube-scheduler-my-little-kubernetes-control-plane_kube-system_kube-scheduler-70e72a8b0441293f5851125efa9392b2a376415565a05231450fc03afecc2668.log
    â”‚Â Â  â””â”€â”€ local-path-provisioner-6bc4bddd6b-km6m4_local-path-storage_local-path-provisioner-e4bf976fb7fcf3c1982817ea5b5de661790dbbe329692fe8b088e8fb316c137d.log
    â”œâ”€â”€ images.log
    â”œâ”€â”€ inspect.json
    â”œâ”€â”€ journal.log
    â”œâ”€â”€ kubelet.log
    â”œâ”€â”€ kubernetes-version.txt
    â”œâ”€â”€ pods
    â”‚Â Â  â”œâ”€â”€ kube-system_coredns-5d78c9869d-m6zfl_db77db26-4fd0-48f1-bbe7-2d3fe81a76d6
    â”‚Â Â  â”‚Â Â  â””â”€â”€ coredns
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_coredns-5d78c9869d-vlv59_9cc23a37-f541-4791-af13-8d27716617e1
    â”‚Â Â  â”‚Â Â  â””â”€â”€ coredns
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_etcd-my-little-kubernetes-control-plane_f5d05561aae79e56e905c4d1a193c022
    â”‚Â Â  â”‚Â Â  â””â”€â”€ etcd
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_kindnet-n6jll_c9569b3f-c56e-4f5f-9715-9fb1031a215a
    â”‚Â Â  â”‚Â Â  â””â”€â”€ kindnet-cni
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_kube-apiserver-my-little-kubernetes-control-plane_ac1c887e1485d5b8bc5ca97574152ce8
    â”‚Â Â  â”‚Â Â  â””â”€â”€ kube-apiserver
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_kube-controller-manager-my-little-kubernetes-control-plane_e154e425b891c8f0922cb29cbb3f2257
    â”‚Â Â  â”‚Â Â  â””â”€â”€ kube-controller-manager
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_kube-proxy-wmvm5_8ce1cae9-0755-423a-a73c-045d5d4745ff
    â”‚Â Â  â”‚Â Â  â””â”€â”€ kube-proxy
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â”œâ”€â”€ kube-system_kube-scheduler-my-little-kubernetes-control-plane_bf4f69d46c370c6dd8446303e1ed7194
    â”‚Â Â  â”‚Â Â  â””â”€â”€ kube-scheduler
    â”‚Â Â  â”‚Â Â      â””â”€â”€ 0.log
    â”‚Â Â  â””â”€â”€ local-path-storage_local-path-provisioner-6bc4bddd6b-km6m4_63c30f86-17b3-4278-ba5d-df1bf83a6d8f
    â”‚Â Â      â””â”€â”€ local-path-provisioner
    â”‚Â Â          â””â”€â”€ 0.log
    â””â”€â”€ serial.log

21 directories, 28 files
```

## DÃ©ploiement d'application

You can use the kubectl command-line tool to deploy an application to your Kind cluster. Create a deployment definition file that contains the specifics of your application. An example deployment definition file for a simple Nginx web server is provided below:

```yaml title="deployment.yaml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-world-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello-world
  template:
    metadata:
      labels:
        app: hello-world
    spec:
      containers:
      - name: hello-world-container
        image: nginx:latest
        ports:
        - containerPort: 80
        readinessProbe:
          httpGet:
            path: /
            port: 80
        livenessProbe:
          httpGet:
            path: /
            port: 80
        startupProbe:
          httpGet:
            path: /
            port: 80
          failureThreshold: 30
          periodSeconds: 10
        resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
```

Save this file asÂ `nginx-deployment.yaml`Â and then run the following command to create the deployment:

```shell hl_lines="1"
kubectl apply -f nginx-deployment.yaml
```

This command will create a deployment with three Nginx web server replicas.

To connect to the web server, you must first create a service that exposes the deployment. The following service definition file can be used to create a service:

```yaml title="service.yaml"
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - name: http
    port: 80
    targetPort: 80
  type: ClusterIP
```

Save this file asÂ `nginx-service.yaml`Â and then run the following command to create the service:

```shell hl_lines="1"
kubectl apply -f nginx-service.yaml
```

This command will create a ClusterIP service, which will expose the Nginx web server deployment.

To obtain the IP address of the service, use theÂ `kubectl get services`Â command. You can access the Nginx web server once you have the IP address by opening a web browser and navigating toÂ `http://<service-ip>:80`.

---

## Conclusion
Plus d'excuse possible, vous savez maintenant dÃ©ployer et configurer un cluster Kubernetes single ou multi-nodes via Kind afin d'y dÃ©ployer toutes sorte d'applications ! Je ne peux que vous conseiller de poursuivre avec l'installation de Helm pour dÃ©ployer Crossplane, Argo CD et Gitlab.


