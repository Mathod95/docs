## KIND

!!! Example "KIND"

    !!! Warning 

        `apiServerAddress` much match your **LOCAL_WSL_IP**

    === "MANAGEMENT"

        ```yaml linenums="1" title="management.yaml"
        kind: Cluster
        apiVersion: kind.x-k8s.io/v1alpha4
        name: management
        networking:
          apiServerAddress: 192.168.1.2
          apiServerPort: 6443
        nodes:
        - role: control-plane
        - role: worker
        - role: worker
        - role: worker
        ```

    === "PRODUCTION"

        ```yaml linenums="1" title="production.yaml"
        kind: Cluster
        apiVersion: kind.x-k8s.io/v1alpha4
        name: production
        networking:
          apiServerAddress: 192.168.1.2
          apiServerPort: 6444
        nodes:
        - role: control-plane
        - role: worker
        - role: worker
        - role: worker
        ```

    === "STAGING"

        ```yaml linenums="1" title="staging.yaml"
        kind: Cluster
        apiVersion: kind.x-k8s.io/v1alpha4
        name: staging
        networking:
          apiServerAddress: 192.168.1.2
          apiServerPort: 6445
        nodes:
        - role: control-plane
        - role: worker
        - role: worker
        - role: worker
        ```

    ```bash hl_lines="1-3"
    kind create cluster --config staging.yaml
    kind create cluster --config production.yaml
    kind create cluster --config management.yaml
    ```

!!! Example "STRUCTURE"

    ```shell title="Structure du dÃ©pÃ´t"
    argocd/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ bootstrap/
    â”‚   â”œâ”€â”€ argocd-values.yaml             # Valeurs initiales d'Argo CD pour Helm
    â”‚   â””â”€â”€ platform-project.yaml          â† AppProject "platform"
    â”‚   â””â”€â”€ app-of-apps.yaml               # Root application (gÃ¨re toutes les autres)
    â”œâ”€â”€ apps/
    â”‚   â”œâ”€â”€ reloader-appset.yaml           â† Generator Git Directory
    â”‚   â”‚                                     Lit: charts/reloader/environments/*
    â”‚   â”‚                                     CrÃ©e: reloader-prod, reloader-staging
    â”‚   â”‚                                     Project: platform
    â”‚   â”‚
    â”‚   â”œâ”€â”€ prometheus-appset.yaml         â† Generator Git Directory
    â”‚   â”‚                                     Lit: charts/prometheus/environments/*
    â”‚   â”‚                                     CrÃ©e: prometheus-prod, prometheus-staging
    â”‚   â”‚                                     Project: platform
    â”‚   â”‚
    â”‚   â””â”€â”€ metrics-server.yaml             â† Generator Git Directory
    â”‚                                         Lit: charts/metrics-server/environments/*
    â”‚                                         CrÃ©e: metrics-server-prod, metrics-server-staging
    â”‚                                         Project: platform
    â””â”€â”€ charts/
        â”œâ”€â”€ reloader/
        â”‚   â”œâ”€â”€ Chart.yaml                 â† Metadata wrapper
        â”‚   â”œâ”€â”€ values.yaml                â† Config COMMUNE (prod + staging)
        â”‚   â”œâ”€â”€ .helmignore
        â”‚   â”œâ”€â”€ environments/
        â”‚   â”‚   â”œâ”€â”€ prod/
        â”‚   â”‚   â”‚   â””â”€â”€ values.yaml       â† Surcharges PROD
        â”‚   â”‚   â””â”€â”€ staging/
        â”‚   â”‚       â””â”€â”€ values.yaml       â† Surcharges STAGING
        â”‚   â”œâ”€â”€ charts/
        â”‚   â”‚   â””â”€â”€ reloader-2.2.6.tgz    â† Chart Stakater (gÃ©nÃ©rÃ©)
        â”‚   â””â”€â”€ templates/
        â”‚       â”œâ”€â”€ service.yaml           â† Ressources additionnelles
        â”‚       â”œâ”€â”€ servicemonitor.yaml
        â”‚       â”œâ”€â”€ network-policy.yaml
        â”‚       â”œâ”€â”€ pod-disruption-budget.yaml
        â”‚       â”œâ”€â”€ priority-class.yaml
        â”‚       â””â”€â”€ _helpers.tpl
        â”‚
        â”œâ”€â”€ prometheus/
        â”‚   â”œâ”€â”€ Chart.yaml
        â”‚   â”œâ”€â”€ values.yaml
        â”‚   â”œâ”€â”€ environments/
        â”‚   â”‚   â”œâ”€â”€ prod/
        â”‚   â”‚   â”‚   â””â”€â”€ values.yaml
        â”‚   â”‚   â””â”€â”€ staging/
        â”‚   â”‚       â””â”€â”€ values.yaml
        â”‚   â”œâ”€â”€ charts/
        â”‚   â”‚   â””â”€â”€ prometheus-25.0.0.tgz
        â”‚   â””â”€â”€ templates/
        â”‚       â””â”€â”€ ...
        â”‚
        â””â”€â”€ metrics-server/
            â”œâ”€â”€ Chart.yaml
            â”œâ”€â”€ values.yaml
            â”œâ”€â”€ environments/
            â”‚   â”œâ”€â”€ prod/
            â”‚   â”‚   â””â”€â”€ values.yaml
            â”‚   â””â”€â”€ staging/
            â”‚       â””â”€â”€ values.yaml
            â””â”€â”€ templates/
                â””â”€â”€ ...
    ```




    ```bash title="CrÃ©er le rÃ©pertoire du dÃ©pÃ´t" hl_lines="1-2"
    mkdir argocd
    cd argocd
    ```

    ```bash title="Initialiser Git" hl_lines="1"
    git init
    ```

    ```bash title="CrÃ©er la structure de rÃ©pertoires" hl_lines="1"
    mkdir -p bootstrap apps manifests/metrics-server
    ```

    ```bash title="Initialiser le dÃ©pÃ´t Git" hl_lines="1-2"
    git add .
    git commit -m "Initial structure"
    ```

    ```bash title="Push vers votre hÃ©bergement Git (GitHub, GitLab, etc.)" hl_lines="1-2"
    git remote add origin https://github.com/YOUR-USERNAME/argocd-gitops.git
    git push -u origin main
    ```


!!! Example "ARGO CD"

    ```bash hl_lines="1" title="Install Argo CD CLI"
    brew install argocd
    ```
    
    === "KUBECTL"

        ```bash hl_lines="1" title="Ensure Management Cluster is selected"
        kubectl config use-context kind-management
        Switched to context "kind-management".
        ```

    === "KUBECTX"

        ```bash hl_lines="1" title="Ensure Management Cluster is selected"
        kubectx kind-management                                                                                             
        Switched to context "kind-management".
        ```

    ```bash hl_lines="1-5" title="Install Argo CD via Helm"
    helm install argocd argo/argo-cd \
      --namespace argocd \
      --create-namespace \
      --values bootstrap/argocd-values.yaml \
      --wait
    ```

    **AJOUTER LA RECUPERATION DU VALUES.YAML DE BASE**

    ```bash hl_lines="1" title="Switch to argocd Namespace"
    kubens argocd
    Context "kind-management" modified.
    Active namespace is "argocd".
    ```

    ```bash hl_lines="1" title="Connect to Argo CD (core mode)"
    argocd login --core
    Context 'kubernetes' updated
    ```

    ```bash 
    # Production
    kubectl --context kind-production create serviceaccount argocd-manager -n kube-system
    kubectl --context kind-production create clusterrolebinding argocd-manager-role-binding \
      --clusterrole=cluster-admin --serviceaccount=kube-system:argocd-manager

    kubectl --context kind-production apply -f - <<'EOF'
    apiVersion: v1
    kind: Secret
    metadata:
      name: argocd-manager-token
      namespace: kube-system
      annotations:
        kubernetes.io/service-account.name: argocd-manager
    type: kubernetes.io/service-account-token
    EOF

    # Staging
    kubectl --context kind-staging create serviceaccount argocd-manager -n kube-system
    kubectl --context kind-staging create clusterrolebinding argocd-manager-role-binding \
      --clusterrole=cluster-admin --serviceaccount=kube-system:argocd-manager

    kubectl --context kind-staging apply -f - <<'EOF'
    apiVersion: v1
    kind: Secret
    metadata:
      name: argocd-manager-token
      namespace: kube-system
      annotations:
        kubernetes.io/service-account.name: argocd-manager
    type: kubernetes.io/service-account-token
    EOF
    ```

    ```bash
    # RÃ©cupÃ©rer les tokens
    echo ""
    echo "RÃ©cupÃ©ration des tokens de service account..."
    PROD_TOKEN=$(kubectl --context kind-production get secret argocd-manager-token -n kube-system -o jsonpath='{.data.token}' | base64 -d)
    STAG_TOKEN=$(kubectl --context kind-staging get secret argocd-manager-token -n kube-system -o jsonpath='{.data.token}' | base64 -d)

    if [ -z "$PROD_TOKEN" ] || [ -z "$STAG_TOKEN" ]; then
        echo "âŒ ERREUR: Impossible de rÃ©cupÃ©rer les tokens!"
        exit 1
    fi

    echo "âœ… Tokens rÃ©cupÃ©rÃ©s avec succÃ¨s"
    ```

    ```bash
    # CrÃ©er les secrets de cluster dans ArgoCD avec les noms Docker
    echo ""
    echo "CrÃ©ation des secrets de cluster dans ArgoCD..."

    kubectl --context kind-management apply -f - <<EOF
    apiVersion: v1
    kind: Secret
    metadata:
      name: production-cluster
      namespace: argocd
      labels:
        argocd.argoproj.io/secret-type: cluster
    type: Opaque
    stringData:
      name: production
      server: https://production-control-plane:6443
      config: |
        {
          "bearerToken": "$PROD_TOKEN",
          "tlsClientConfig": {
            "insecure": true
          }
        }
    ---
    apiVersion: v1
    kind: Secret
    metadata:
      name: staging-cluster
      namespace: argocd
      labels:
        argocd.argoproj.io/secret-type: cluster
    type: Opaque
    stringData:
      name: staging
      server: https://staging-control-plane:6443
      config: |
        {
          "bearerToken": "$STAG_TOKEN",
          "tlsClientConfig": {
            "insecure": true
          }
        }
    EOF
    ```




















    
!!! Example "ARGO CD AUTOPILOT"

    ```bash hl_lines="1" title="Install argocd-autopilot CLI"
    brew install argocd-autopilot
    ```

    ```bash hl_lines="1-2" title="Set up Git credentials"
    export GIT_TOKEN=<your-git-token>
    export GIT_REPO=<your-repo-url>
    ```

    ```bash hl_lines="1" title="Bootstrap ArgoCD in HA mode"
    argocd-autopilot repo bootstrap --app https://github.com/argoproj-labs/argocd-autopilot/manifests/ha
    ```
    ??? quote "OUTPUT"

        ```bash hl_lines="1"
        argocd-autopilot repo bootstrap --app https://github.com/argoproj-labs/argocd-autopilot/manifests/ha
        INFO cloning repo: https://gitlab.com/mathod-io/infrastructure/services/argocd.git
        Enumerating objects: 2, done.
        Counting objects: 100% (2/2), done.
        Total 2 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)
        INFO using revision: "", installation path: ""
        INFO using context: "kind-management", namespace: "argocd"
        INFO applying bootstrap manifests to cluster...
        namespace/argocd created
        I1214 13:18:48.012999   49532 warnings.go:110] "Warning: unrecognized format \"int64\""
        customresourcedefinition.apiextensions.k8s.io/applications.argoproj.io created
        I1214 13:18:48.249233   49532 warnings.go:110] "Warning: unrecognized format \"int64\""
        customresourcedefinition.apiextensions.k8s.io/applicationsets.argoproj.io created
        I1214 13:18:48.430214   49532 warnings.go:110] "Warning: unrecognized format \"int64\""
        customresourcedefinition.apiextensions.k8s.io/appprojects.argoproj.io created
        serviceaccount/argocd-application-controller created
        serviceaccount/argocd-applicationset-controller created
        serviceaccount/argocd-dex-server created
        serviceaccount/argocd-notifications-controller created
        serviceaccount/argocd-redis-ha created
        serviceaccount/argocd-redis-ha-haproxy created
        serviceaccount/argocd-repo-server created
        serviceaccount/argocd-server created
        role.rbac.authorization.k8s.io/argocd-application-controller created
        role.rbac.authorization.k8s.io/argocd-applicationset-controller created
        role.rbac.authorization.k8s.io/argocd-dex-server created
        role.rbac.authorization.k8s.io/argocd-notifications-controller created
        role.rbac.authorization.k8s.io/argocd-redis-ha created
        role.rbac.authorization.k8s.io/argocd-redis-ha-haproxy created
        role.rbac.authorization.k8s.io/argocd-server created
        clusterrole.rbac.authorization.k8s.io/argocd-application-controller created
        clusterrole.rbac.authorization.k8s.io/argocd-applicationset-controller created
        clusterrole.rbac.authorization.k8s.io/argocd-server created
        rolebinding.rbac.authorization.k8s.io/argocd-application-controller created
        rolebinding.rbac.authorization.k8s.io/argocd-applicationset-controller created
        rolebinding.rbac.authorization.k8s.io/argocd-dex-server created
        rolebinding.rbac.authorization.k8s.io/argocd-notifications-controller created
        rolebinding.rbac.authorization.k8s.io/argocd-redis-ha created
        rolebinding.rbac.authorization.k8s.io/argocd-redis-ha-haproxy created
        rolebinding.rbac.authorization.k8s.io/argocd-server created
        clusterrolebinding.rbac.authorization.k8s.io/argocd-application-controller created
        clusterrolebinding.rbac.authorization.k8s.io/argocd-applicationset-controller created
        clusterrolebinding.rbac.authorization.k8s.io/argocd-server created
        configmap/argocd-cm created
        configmap/argocd-cmd-params-cm created
        configmap/argocd-gpg-keys-cm created
        configmap/argocd-notifications-cm created
        configmap/argocd-rbac-cm created
        configmap/argocd-redis-ha-configmap created
        configmap/argocd-redis-ha-health-configmap created
        configmap/argocd-ssh-known-hosts-cm created
        configmap/argocd-tls-certs-cm created
        secret/argocd-notifications-secret created
        secret/argocd-secret created
        service/argocd-applicationset-controller created
        service/argocd-dex-server created
        service/argocd-metrics created
        service/argocd-notifications-controller-metrics created
        I1214 13:18:49.864417   49532 warnings.go:110] "Warning: spec.SessionAffinity is ignored for headless services"
        service/argocd-redis-ha created
        service/argocd-redis-ha-announce-0 created
        service/argocd-redis-ha-announce-1 created
        service/argocd-redis-ha-announce-2 created
        service/argocd-redis-ha-haproxy created
        service/argocd-repo-server created
        service/argocd-server created
        service/argocd-server-metrics created
        deployment.apps/argocd-applicationset-controller created
        deployment.apps/argocd-dex-server created
        deployment.apps/argocd-notifications-controller created
        deployment.apps/argocd-redis-ha-haproxy created
        deployment.apps/argocd-repo-server created
        deployment.apps/argocd-server created
        statefulset.apps/argocd-application-controller created
        statefulset.apps/argocd-redis-ha-server created
        networkpolicy.networking.k8s.io/argocd-application-controller-network-policy created
        networkpolicy.networking.k8s.io/argocd-applicationset-controller-network-policy created
        networkpolicy.networking.k8s.io/argocd-dex-server-network-policy created
        networkpolicy.networking.k8s.io/argocd-notifications-controller-network-policy created
        networkpolicy.networking.k8s.io/argocd-redis-ha-proxy-network-policy created
        networkpolicy.networking.k8s.io/argocd-redis-ha-server-network-policy created
        networkpolicy.networking.k8s.io/argocd-repo-server-network-policy created
        networkpolicy.networking.k8s.io/argocd-server-network-policy created
        secret/argocd-repo-creds created

        INFO pushing bootstrap manifests to repo
        INFO applying argo-cd bootstrap application
        I1214 13:20:24.317974   49532 warnings.go:110] "Warning: metadata.finalizers: \"resources-finalizer.argocd.argoproj.io\": prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers"
        application.argoproj.io/autopilot-bootstrap created
        INFO running argocd login to initialize argocd config
        E1214 13:20:24.399201   49532 portforward.go:391] "Unhandled Error" err="error copying from remote stream to local connection: readfrom tcp4 127.0.0.1:43889->127.0.0.1:60354: write tcp4 127.0.0.1:43889->127.0.0.1:60354: write: broken pipe" logger="UnhandledError"
        'admin:login' logged in successfully
        Context 'autopilot' updated

        INFO argocd initialized. password: s3GoqZRYAACFDnzM
        INFO run:

            kubectl port-forward -n argocd svc/argocd-server 8080:80
        ```

    ```bash hl_lines="1" title="Switch to Management Cluster"
    kubectx kind-management
    Switched to context "kind-management".
    ```

    ```bash hl_lines="1" title="Switch to argocd Namespace"
    kubens argocd
    Context "kind-management" modified.
    Active namespace is "argocd".
    ```

    ```bash hl_lines="1" title="Connect to Argo CD (core mode)"
    argocd login --core
    Context 'kubernetes' updated
    ```

    ??? Tip "List available Cluster"
        ```bash hl_lines="1"
        argocd cluster add
        {"level":"error","msg":"Choose a context name from:","time":"2025-12-14T13:33:35+01:00"}
        CURRENT  NAME             CLUSTER          SERVER
        *        kind-management  kind-management  https://192.168.1.2:6443
                  kind-production  kind-production  https://192.168.1.2:6444
                  kind-staging     kind-staging     https://192.168.1.2:6445
        ```

    ```bash hl_lines="1" title="Add Cluster Production"
    argocd cluster add kind-production
    WARNING: This will create a service account `argocd-manager` on the cluster referenced by context `kind-production` with full cluster level privileges. Do you want to continue [y/N]? y
    {"level":"info","msg":"ServiceAccount \"argocd-manager\" created in namespace \"kube-system\"","time":"2025-12-14T13:37:56+01:00"}
    {"level":"info","msg":"ClusterRole \"argocd-manager-role\" created","time":"2025-12-14T13:37:56+01:00"}
    {"level":"info","msg":"ClusterRoleBinding \"argocd-manager-role-binding\" created","time":"2025-12-14T13:37:56+01:00"}
    {"level":"info","msg":"Created bearer token secret \"argocd-manager-long-lived-token\" for ServiceAccount \"argocd-manager\"","time":"2025-12-14T13:37:56+01:00"}
    {"execID":"277f9","level":"error","msg":"`helm version --client --short` failed exit status 1: Error: unknown flag: --client","time":"2025-12-14T13:37:57+01:00"}
    Cluster 'https://192.168.1.2:6444' added
    ```

    ```bash hl_lines="1" title="Add Cluster Staging"
    argocd cluster add kind-staging
    WARNING: This will create a service account `argocd-manager` on the cluster referenced by context `kind-staging` with full cluster level privileges. Do you want to continue [y/N]? y
    {"level":"info","msg":"ServiceAccount \"argocd-manager\" created in namespace \"kube-system\"","time":"2025-12-14T13:38:07+01:00"}
    {"level":"info","msg":"ClusterRole \"argocd-manager-role\" created","time":"2025-12-14T13:38:07+01:00"}
    {"level":"info","msg":"ClusterRoleBinding \"argocd-manager-role-binding\" created","time":"2025-12-14T13:38:07+01:00"}
    {"level":"info","msg":"Created bearer token secret \"argocd-manager-long-lived-token\" for ServiceAccount \"argocd-manager\"","time":"2025-12-14T13:38:07+01:00"}
    {"execID":"c2c02","level":"error","msg":"`helm version --client --short` failed exit status 1: Error: unknown flag: --client","time":"2025-12-14T13:38:07+01:00"}
    Cluster 'https://192.168.1.2:6445' added
    ```


??? TIP "SUPERSCRIPT AUTOPILOT"

    ```bash linenums="1"
    #!/bin/bash
    set -e

    echo "=========================================="
    echo "Setup ArgoCD Autopilot - 3 Clusters KIND"
    echo "=========================================="

    # Configuration Git
    export GIT_TOKEN=
    export GIT_REPO=https://gitlab.com/mathod-io/infrastructure/services/argocd.git

    echo "Git Repository: $GIT_REPO"

    # CrÃ©er les fichiers de configuration
    echo ""
    echo "CrÃ©ation des fichiers de configuration KIND..."

    cat > /tmp/management.yaml <<'EOF'
    kind: Cluster
    apiVersion: kind.x-k8s.io/v1alpha4
    name: management
    networking:
      apiServerAddress: 192.168.1.2
      apiServerPort: 6443
    nodes:
    - role: control-plane
    - role: worker
    - role: worker
    - role: worker
    EOF

    cat > /tmp/production.yaml <<'EOF'
    kind: Cluster
    apiVersion: kind.x-k8s.io/v1alpha4
    name: production
    networking:
      apiServerAddress: 192.168.1.2
      apiServerPort: 6444
    nodes:
    - role: control-plane
    - role: worker
    - role: worker
    - role: worker
    EOF

    cat > /tmp/staging.yaml <<'EOF'
    kind: Cluster
    apiVersion: kind.x-k8s.io/v1alpha4
    name: staging
    networking:
      apiServerAddress: 192.168.1.2
      apiServerPort: 6445
    nodes:
    - role: control-plane
    - role: worker
    - role: worker
    - role: worker
    EOF

    # CrÃ©er les clusters
    echo ""
    echo "CrÃ©ation des clusters KIND..."
    echo "  - Management (port 6443)..."
    kind create cluster --config /tmp/management.yaml

    echo "  - Production (port 6444)..."
    kind create cluster --config /tmp/production.yaml

    echo "  - Staging (port 6445)..."
    kind create cluster --config /tmp/staging.yaml

    # VÃ©rifier le rÃ©seau
    echo ""
    echo "VÃ©rification de la configuration rÃ©seau..."
    MGMT_NET=$(docker inspect management-control-plane --format '{{range $k, $v := .NetworkSettings.Networks}}{{$k}}{{end}}')
    PROD_NET=$(docker inspect production-control-plane --format '{{range $k, $v := .NetworkSettings.Networks}}{{$k}}{{end}}')
    STAG_NET=$(docker inspect staging-control-plane --format '{{range $k, $v := .NetworkSettings.Networks}}{{$k}}{{end}}')

    echo "MANAGEMENT sur rÃ©seau: $MGMT_NET"
    echo "PRODUCTION sur rÃ©seau: $PROD_NET"
    echo "STAGING sur rÃ©seau: $STAG_NET"

    if [ "$MGMT_NET" != "$PROD_NET" ] || [ "$MGMT_NET" != "$STAG_NET" ]; then
        echo "âš ï¸  ATTENTION: Les clusters ne sont pas tous sur le mÃªme rÃ©seau Docker!"
    fi

    echo ""
    echo "Conteneurs Docker crÃ©Ã©s:"
    docker ps --filter name=control-plane --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    docker ps --filter name=worker --format "table {{.Names}}\t{{.Status}}"

    # Installer ArgoCD Autopilot
    echo ""
    echo "Installation d'ArgoCD Autopilot en mode HA..."
    kubectl config use-context kind-management

    argocd-autopilot repo bootstrap \
      --app https://github.com/argoproj-labs/argocd-autopilot/manifests/ha \
      --repo $GIT_REPO

    echo ""
    echo "Attente que tous les pods ArgoCD soient prÃªts..."
    kubectl --context kind-management wait --for=condition=available --timeout=300s -n argocd deployment/argocd-server
    kubectl --context kind-management wait --for=condition=available --timeout=300s -n argocd deployment/argocd-repo-server
    kubectl --context kind-management wait --for=condition=available --timeout=300s -n argocd deployment/argocd-applicationset-controller

    # Switch to argocd namespace
    echo ""
    echo "Configuration du contexte kubectl..."
    kubectl config set-context kind-management --namespace=argocd
    kubectl config use-context kind-management

    # Login to ArgoCD in core mode
    echo ""
    echo "Connexion Ã  ArgoCD (core mode)..."
    argocd login --core

    # CrÃ©er manuellement les service accounts sur les autres clusters
    echo ""
    echo "CrÃ©ation des service accounts sur production et staging..."

    # Production
    kubectl --context kind-production create serviceaccount argocd-manager -n kube-system
    kubectl --context kind-production create clusterrolebinding argocd-manager-role-binding \
      --clusterrole=cluster-admin --serviceaccount=kube-system:argocd-manager

    kubectl --context kind-production apply -f - <<'EOF'
    apiVersion: v1
    kind: Secret
    metadata:
      name: argocd-manager-token
      namespace: kube-system
      annotations:
        kubernetes.io/service-account.name: argocd-manager
    type: kubernetes.io/service-account-token
    EOF

    # Staging
    kubectl --context kind-staging create serviceaccount argocd-manager -n kube-system
    kubectl --context kind-staging create clusterrolebinding argocd-manager-role-binding \
      --clusterrole=cluster-admin --serviceaccount=kube-system:argocd-manager

    kubectl --context kind-staging apply -f - <<'EOF'
    apiVersion: v1
    kind: Secret
    metadata:
      name: argocd-manager-token
      namespace: kube-system
      annotations:
        kubernetes.io/service-account.name: argocd-manager
    type: kubernetes.io/service-account-token
    EOF

    echo "Attente de la crÃ©ation des tokens..."
    sleep 10

    # RÃ©cupÃ©rer les tokens
    echo ""
    echo "RÃ©cupÃ©ration des tokens de service account..."
    PROD_TOKEN=$(kubectl --context kind-production get secret argocd-manager-token -n kube-system -o jsonpath='{.data.token}' | base64 -d)
    STAG_TOKEN=$(kubectl --context kind-staging get secret argocd-manager-token -n kube-system -o jsonpath='{.data.token}' | base64 -d)

    if [ -z "$PROD_TOKEN" ] || [ -z "$STAG_TOKEN" ]; then
        echo "âŒ ERREUR: Impossible de rÃ©cupÃ©rer les tokens!"
        exit 1
    fi

    echo "âœ… Tokens rÃ©cupÃ©rÃ©s avec succÃ¨s"

    # CrÃ©er les secrets de cluster dans ArgoCD avec les noms Docker
    echo ""
    echo "CrÃ©ation des secrets de cluster dans ArgoCD..."

    kubectl --context kind-management apply -f - <<EOF
    apiVersion: v1
    kind: Secret
    metadata:
      name: production-cluster
      namespace: argocd
      labels:
        argocd.argoproj.io/secret-type: cluster
    type: Opaque
    stringData:
      name: production
      server: https://production-control-plane:6443
      config: |
        {
          "bearerToken": "$PROD_TOKEN",
          "tlsClientConfig": {
            "insecure": true
          }
        }
    ---
    apiVersion: v1
    kind: Secret
    metadata:
      name: staging-cluster
      namespace: argocd
      labels:
        argocd.argoproj.io/secret-type: cluster
    type: Opaque
    stringData:
      name: staging
      server: https://staging-control-plane:6443
      config: |
        {
          "bearerToken": "$STAG_TOKEN",
          "tlsClientConfig": {
            "insecure": true
          }
        }
    EOF

    # Renommer le cluster in-cluster en management
    echo ""
    echo "Renommage du cluster in-cluster -> management..."
    INCLUSTER_SECRET=$(kubectl --context kind-management get secret -n argocd -l argocd.argoproj.io/secret-type=cluster -o name | grep -v production | grep -v staging | head -1)

    if [ -n "$INCLUSTER_SECRET" ]; then
        kubectl --context kind-management patch $INCLUSTER_SECRET -n argocd \
          --type merge \
          -p '{"stringData":{"name":"management"}}'
    fi

    # RedÃ©marrer ArgoCD pour prendre en compte les nouveaux clusters
    echo ""
    echo "RedÃ©marrage d'ArgoCD..."
    kubectl --context kind-management rollout restart -n argocd statefulset/argocd-application-controller
    kubectl --context kind-management rollout restart -n argocd deployment/argocd-server
    kubectl --context kind-management rollout status -n argocd statefulset/argocd-application-controller --timeout=180s
    kubectl --context kind-management rollout status -n argocd deployment/argocd-server --timeout=180s

    # RÃ©cupÃ©rer le mot de passe ArgoCD
    echo ""
    echo "RÃ©cupÃ©ration du mot de passe ArgoCD..."
    sleep 5
    ARGOCD_PASSWORD=$(kubectl --context kind-management get secret argocd-initial-admin-secret -n argocd -o jsonpath="{.data.password}" | base64 -d 2>/dev/null || echo "Voir logs autopilot bootstrap")

    # CrÃ©er les projets ArgoCD Autopilot
    echo ""
    echo "CrÃ©ation des projets ArgoCD Autopilot..."

    argocd-autopilot project create management \
      --dest-server https://kubernetes.default.svc 2>/dev/null || echo "  â„¹ï¸  Projet management existe dÃ©jÃ "

    argocd-autopilot project create production \
      --dest-server https://production-control-plane:6443 2>/dev/null || echo "  â„¹ï¸  Projet production existe dÃ©jÃ "

    argocd-autopilot project create staging \
      --dest-server https://staging-control-plane:6443 2>/dev/null || echo "  â„¹ï¸  Projet staging existe dÃ©jÃ "

    # Attendre que ArgoCD reconnaisse les clusters
    echo ""
    echo "Attente de la synchronisation ArgoCD..."
    sleep 15

    echo ""
    echo "=========================================="
    echo "âœ… Installation terminÃ©e avec succÃ¨s!"
    echo "=========================================="
    echo ""
    echo "ğŸ“¦ ArgoCD Autopilot (HA mode)"
    echo "   Git Repository: $GIT_REPO"
    if [ "$ARGOCD_PASSWORD" != "Voir logs autopilot bootstrap" ]; then
        echo "   Password: $ARGOCD_PASSWORD"
    fi
    echo ""
    echo "ğŸ¯ Clusters KIND crÃ©Ã©s:"
    echo "   - MANAGEMENT: 1 control-plane + 3 workers (192.168.1.2:6443)"
    echo "   - PRODUCTION: 1 control-plane + 3 workers (192.168.1.2:6444)"
    echo "   - STAGING:    1 control-plane + 3 workers (192.168.1.2:6445)"
    echo ""
    echo "ğŸ“ Projets ArgoCD Autopilot:"
    echo "   - management  â†’ https://kubernetes.default.svc"
    echo "   - production  â†’ https://production-control-plane:6443"
    echo "   - staging     â†’ https://staging-control-plane:6443"
    echo ""
    echo "ğŸ”§ Commandes utiles:"
    echo "   # Port-forward ArgoCD UI"
    echo "   kubectl port-forward -n argocd svc/argocd-server 8080:80"
    echo ""
    echo "   # VÃ©rifier les clusters"
    echo "   argocd cluster list"
    echo ""
    echo "   # VÃ©rifier les projets"
    echo "   argocd proj list"
    echo ""
    echo "   # CrÃ©er une app dans un projet"
    echo "   argocd-autopilot app create <app-name> --app <manifest-url> --project production"
    echo ""
    echo "=========================================="
    echo ""

    # Afficher l'Ã©tat final
    echo "ğŸ“Š Ã‰tat des clusters ArgoCD:"
    argocd cluster list 2>/dev/null || echo "ExÃ©cutez: argocd login --core"

    echo ""
    echo "ğŸ“‹ Projets ArgoCD:"
    argocd proj list 2>/dev/null || true

    echo ""
    echo "ğŸ® Nodes Management:"
    kubectl --context kind-management get nodes

    echo ""
    echo "âœ¨ Setup terminÃ©! Bon dÃ©veloppement! ğŸš€"
    ```